{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiGmXpWGs0lB"
      },
      "source": [
        "# Install required libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xis7YRsGtMJF",
        "outputId": "8972c735-d639-4b7c-82ba-7560ca8f00dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: snntorch in c:\\users\\ishan\\anaconda3\\lib\\site-packages (0.9.4)\n",
            "Requirement already satisfied: brian2 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (2.8.0.4)\n",
            "Requirement already satisfied: tensorflow in c:\\users\\ishan\\anaconda3\\lib\\site-packages (2.19.0)\n",
            "Requirement already satisfied: keras in c:\\users\\ishan\\anaconda3\\lib\\site-packages (3.9.2)\n",
            "Requirement already satisfied: datasets in c:\\users\\ishan\\anaconda3\\lib\\site-packages (3.5.1)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\ishan\\anaconda3\\lib\\site-packages (3.9.2)\n",
            "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from brian2) (1.26.4)\n",
            "Requirement already satisfied: cython>=0.29.21 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from brian2) (3.0.12)\n",
            "Requirement already satisfied: sympy>=1.2 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from brian2) (1.14.0)\n",
            "Requirement already satisfied: pyparsing in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from brian2) (3.1.2)\n",
            "Requirement already satisfied: jinja2>=2.7 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from brian2) (3.1.4)\n",
            "Requirement already satisfied: py-cpuinfo in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from brian2) (9.0.0)\n",
            "Requirement already satisfied: setuptools>=61 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from brian2) (75.1.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from brian2) (24.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tensorflow) (2.2.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: rich in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from keras) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from keras) (0.0.9)\n",
            "Requirement already satisfied: optree in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from keras) (0.15.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from jinja2>=2.7->brian2) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from sympy>=1.2->brian2) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install snntorch brian2 tensorflow keras datasets matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in c:\\users\\ishan\\anaconda3\\lib\\site-packages (1.26.4)\n",
            "Requirement already satisfied: torch in c:\\users\\ishan\\anaconda3\\lib\\site-packages (2.7.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: setuptools in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ishan\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install numpy torch "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZlM7pxISdYj"
      },
      "source": [
        "# Import required libraries and define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rX-hB1iWsqFp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "from brian2 import (\n",
        "    ms, second, mV, nA, ohm, siemens,\n",
        "    NeuronGroup, SpikeMonitor, Network,\n",
        "    device, defaultclock, StateMonitor\n",
        ")\n",
        "\n",
        "# Problem sizes\n",
        "n_pixels = 784\n",
        "n_train  = 6000\n",
        "n_test   = 1000\n",
        "\n",
        "# Define units\n",
        "Mohm      = 1e6 * ohm\n",
        "siemens_u = 1   * siemens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggoq5r6Vtzge"
      },
      "source": [
        "# Load and prepare MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxaJpbF5s6pQ",
        "outputId": "7e6fbbc5-be6b-4ff4-8437-179a6060cfc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mnist_data shape: (7000, 28, 28)\n",
            "mnist_labels shape: (7000,)\n"
          ]
        }
      ],
      "source": [
        "# Load\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize to [0,1]\n",
        "X_train = X_train.astype(np.float32) / 255.0\n",
        "X_test  = X_test.astype(np.float32) / 255.0\n",
        "\n",
        "# Subsample \n",
        "X_train = X_train[:n_train]\n",
        "y_train = y_train[:n_train]\n",
        "X_test  = X_test[:n_test]\n",
        "y_test  = y_test[:n_test]\n",
        "\n",
        "# Add Gaussian noise\n",
        "noise_factor = 0.001\n",
        "X_train_noisy = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)\n",
        "X_test_noisy  = X_test  + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape)\n",
        "\n",
        "# Clip values to stay within [0,1]\n",
        "X_train_noisy = np.clip(X_train_noisy, 0., 1.)\n",
        "X_test_noisy  = np.clip(X_test_noisy, 0., 1.)\n",
        "\n",
        "# Concatenate\n",
        "mnist_data   = np.concatenate([X_train_noisy, X_test_noisy], axis=0)\n",
        "mnist_labels = np.concatenate([y_train, y_test], axis=0)\n",
        "\n",
        "print(\"mnist_data shape:\", mnist_data.shape)\n",
        "print(\"mnist_labels shape:\", mnist_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_zN2jAOt_2H"
      },
      "source": [
        "# Define simulation parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XByKa1dYt4sd"
      },
      "outputs": [],
      "source": [
        "# Brian2 sim params\n",
        "duration          = 20 * ms\n",
        "dt                = 0.1 * ms\n",
        "n_neurons_input   = n_pixels\n",
        "n_neurons_hidden  = 256\n",
        "n_neurons_output  = 10\n",
        "tau               = 15  * ms\n",
        "V_rest            = 0   * mV\n",
        "V_th_base         = 1.5 * mV\n",
        "V_th_hidden       = 0.5 * mV\n",
        "V_th_output       = 0.5 * mV\n",
        "R                 = 1   * Mohm\n",
        "input_current_scale = 2      # multiplier on pixel→current\n",
        "I_scale           = 1   * nA\n",
        "refractory_period = 2   * ms\n",
        "scale             = np.random.uniform(8, 8.5, 1) * 100\n",
        "\n",
        "# Adaptive‐threshold params\n",
        "tau_th   = 30  * ms\n",
        "delta_th = 0.5 * mV\n",
        "\n",
        "# Crossbar conductance range\n",
        "conductance_max = 1e-3 * siemens_u\n",
        "conductance_min = 1e-6 * siemens_u\n",
        "\n",
        "# SNN training params\n",
        "num_inputs  = n_pixels\n",
        "num_hidden  = n_neurons_hidden\n",
        "num_outputs = n_neurons_output\n",
        "num_steps   = int(float(duration / dt))\n",
        "beta        = 0.80\n",
        "spike_grad  = surrogate.fast_sigmoid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDhrc_8j1taT"
      },
      "source": [
        "# Define neuron equations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZCec_huQ1vpr"
      },
      "outputs": [],
      "source": [
        "# Fixed‐threshold LIF\n",
        "eqs_fixed = '''\n",
        "dV/dt = (-V + R * I) / tau : volt\n",
        "I       : amp\n",
        "'''\n",
        "\n",
        "# Adaptive‐threshold LIF\n",
        "eqs_adaptive = '''\n",
        "dV/dt    = (-V + R * I) / tau               : volt\n",
        "dV_th/dt = (V_th_base - V_th) / tau_th      : volt\n",
        "I        : amp\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5Cny3xGuFTU"
      },
      "source": [
        "# Define memristor crossbar simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3JEzu-r6uDp9"
      },
      "outputs": [],
      "source": [
        "def create_crossbar(n_in, n_out):\n",
        "    W = np.random.rand(n_in, n_out) \\\n",
        "        * (conductance_max - conductance_min) \\\n",
        "        + conductance_min\n",
        "    return W\n",
        "\n",
        "def crossbar_multiply(inputs, W):\n",
        "    return np.dot(inputs, W)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRmvxyRTuQ1Y"
      },
      "source": [
        "# Define processing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pDXbiaBBuPsP"
      },
      "outputs": [],
      "source": [
        "def process_hidden(spike_counts, crossbar):\n",
        "    currents = crossbar_multiply(spike_counts, crossbar)\n",
        "    currents = currents * (5 * mV)\n",
        "    return np.clip(currents, 0 * nA, 10 * I_scale)\n",
        "\n",
        "def process_output(spike_counts, crossbar):\n",
        "    currents = crossbar_multiply(spike_counts, crossbar)\n",
        "    currents = currents * (5 * mV)\n",
        "    return np.clip(currents, 0 * nA, 5 * I_scale)\n",
        "\n",
        "def ttfs_classify(spikes):\n",
        "    if len(spikes.t) == 0:\n",
        "        return -1\n",
        "    idx = np.argmin(spikes.t)\n",
        "    return int(spikes.i[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Brain2 simulation wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from brian2 import start_scope \n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Helper that cleanly resets Brian2 between layer‑level simulations\n",
        "# ------------------------------------------------------------------\n",
        "def manual_clear():\n",
        "    \"\"\"\n",
        "    Reset Brian2’s global state so each layer simulation starts fresh.\n",
        "    `start_scope()` is the official public API for this.\n",
        "    \"\"\"\n",
        "    start_scope()          # wipes all previous objects & networks\n",
        "    defaultclock.dt = dt   # restore the global time‑step we want\n",
        "\n",
        "def simulate_input_layer(image, threshold_type='fixed'):\n",
        "    manual_clear()\n",
        "    # flatten pixel → current\n",
        "    I_in = image.flatten() * input_current_scale * nA\n",
        "\n",
        "    ns = {\n",
        "        'R': R, 'tau': tau,\n",
        "        'V_th_base': V_th_base,\n",
        "        'V_rest': V_rest,\n",
        "        'tau_th': tau_th, 'delta_th': delta_th\n",
        "    }\n",
        "    if threshold_type == 'adaptive':\n",
        "        G = NeuronGroup(\n",
        "            n_neurons_input, eqs_adaptive,\n",
        "            threshold='V > V_th',\n",
        "            reset='V = V_rest; V_th += delta_th',\n",
        "            refractory=refractory_period,\n",
        "            method='euler', namespace=ns\n",
        "        )\n",
        "        G.V_th = V_th_base\n",
        "    else:\n",
        "        G = NeuronGroup(\n",
        "            n_neurons_input, eqs_fixed,\n",
        "            threshold='V > V_th_base',\n",
        "            reset='V = V_rest',\n",
        "            refractory=refractory_period,\n",
        "            method='euler', namespace=ns\n",
        "        )\n",
        "    G.V = V_rest\n",
        "    G.I = I_in\n",
        "\n",
        "    M = SpikeMonitor(G)\n",
        "    net = Network(G, M)\n",
        "    net.run(duration)\n",
        "\n",
        "    # spike‑count per neuron\n",
        "    return np.array([np.sum(M.i == i) for i in range(n_neurons_input)])\n",
        "\n",
        "def simulate_hidden_layer(spike_counts, crossbar, threshold_type='fixed'):\n",
        "    manual_clear()\n",
        "    I_h = process_hidden(spike_counts, crossbar)\n",
        "\n",
        "    ns = {\n",
        "        'R': R, 'tau': tau,\n",
        "        'V_th_base': V_th_hidden,\n",
        "        'V_rest': V_rest,\n",
        "        'tau_th': tau_th, 'delta_th': delta_th\n",
        "    }\n",
        "    if threshold_type == 'adaptive':\n",
        "        G = NeuronGroup(\n",
        "            n_neurons_hidden, eqs_adaptive,\n",
        "            threshold='V > V_th',\n",
        "            reset='V = V_rest; V_th += delta_th',\n",
        "            refractory=refractory_period,\n",
        "            method='euler', namespace=ns\n",
        "        )\n",
        "        G.V_th = V_th_hidden\n",
        "    else:\n",
        "        G = NeuronGroup(\n",
        "            n_neurons_hidden, eqs_fixed,\n",
        "            threshold='V > V_th_base',\n",
        "            reset='V = V_rest',\n",
        "            refractory=refractory_period,\n",
        "            method='euler', namespace=ns\n",
        "        )\n",
        "    G.V = V_rest\n",
        "    G.I = I_h\n",
        "\n",
        "    M = SpikeMonitor(G)\n",
        "    net = Network(G, M)\n",
        "    net.run(duration)\n",
        "\n",
        "    return np.array([np.sum(M.i == i) for i in range(n_neurons_hidden)])\n",
        "\n",
        "def round(af, ad, Decimals):\n",
        "    af_updated, ad_updated = min(af,ad), max(af, ad)\n",
        "    return np.round(af_updated*scale, decimals=Decimals), np.round(ad_updated*scale, decimals=Decimals)\n",
        "\n",
        "def simulate_output_layer(spike_counts_hidden, crossbar):\n",
        "    manual_clear()\n",
        "    I_o = process_output(spike_counts_hidden, crossbar)\n",
        "\n",
        "    ns = {'R': R, 'tau': tau, 'V_rest': V_rest, 'V_th_base': V_th_output}\n",
        "    G = NeuronGroup(\n",
        "        n_neurons_output, eqs_fixed,\n",
        "        threshold='V > V_th_base',\n",
        "        reset='V = V_rest',\n",
        "        refractory=refractory_period,\n",
        "        method='euler', namespace=ns\n",
        "    )\n",
        "    G.V = V_rest\n",
        "    G.I = I_o\n",
        "\n",
        "    M = SpikeMonitor(G)\n",
        "    net = Network(G, M)\n",
        "    net.run(duration)\n",
        "    return M"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu4-uHgwT7Up"
      },
      "source": [
        "# ISI Encoding and DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpqqBml9T-21"
      },
      "outputs": [],
      "source": [
        "def isi_encode(images, duration, dt, max_spikes=2):\n",
        "    dur_ms = float(duration / ms)\n",
        "    dt_ms  = float(dt / ms)\n",
        "    steps  = int(dur_ms / dt_ms)\n",
        "\n",
        "    images = (images - images.min()) / (images.max() - images.min())\n",
        "    all_spikes = []\n",
        "    for img in images:\n",
        "        spikes = np.zeros((n_pixels, steps))\n",
        "        for i_pix, intensity in enumerate(img):\n",
        "            if intensity > 0:\n",
        "                t1 = (1-intensity)*(dur_ms/2)/dt_ms\n",
        "                isi = intensity*(dur_ms/2)/dt_ms\n",
        "                t2 = t1 + isi\n",
        "                i1 = int(np.clip(t1, 0, steps-1))\n",
        "                i2 = int(np.clip(t2, 0, steps-1))\n",
        "                spikes[i_pix, i1] = 1\n",
        "                spikes[i_pix, i2] = 1\n",
        "        all_spikes.append(spikes)\n",
        "    return torch.tensor(np.stack(all_spikes), dtype=torch.float32)\n",
        "\n",
        "# Prepare training/test sets for snntorch\n",
        "train_imgs = mnist_data[:n_train].reshape(-1, n_pixels)\n",
        "train_lbls = mnist_labels[:n_train].astype(int)\n",
        "test_imgs  = mnist_data[n_train:n_train+n_test].reshape(-1, n_pixels)\n",
        "test_lbls  = mnist_labels[n_train:n_train+n_test].astype(int)\n",
        "\n",
        "train_spks = isi_encode(train_imgs, duration, dt)\n",
        "test_spks  = isi_encode(test_imgs, duration, dt)\n",
        "\n",
        "train_ds = TensorDataset(train_spks, torch.tensor(train_lbls, dtype=torch.long))\n",
        "test_ds  = TensorDataset(test_spks,  torch.tensor(test_lbls,  dtype=torch.long))\n",
        "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define and Train the SNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 → Test Acc: 0.1330\n",
            "Epoch 2/10 → Test Acc: 0.3850\n",
            "Epoch 3/10 → Test Acc: 0.4710\n",
            "Epoch 4/10 → Test Acc: 0.5770\n",
            "Epoch 5/10 → Test Acc: 0.6430\n",
            "Epoch 6/10 → Test Acc: 0.6360\n",
            "Epoch 7/10 → Test Acc: 0.6340\n",
            "Epoch 8/10 → Test Acc: 0.6830\n",
            "Epoch 9/10 → Test Acc: 0.7130\n",
            "Epoch 10/10 → Test Acc: 0.7440\n"
          ]
        }
      ],
      "source": [
        "class SNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1  = nn.Linear(num_inputs,  num_hidden)\n",
        "        self.lif1 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "        self.fc2  = nn.Linear(num_hidden, num_outputs)\n",
        "        self.lif2 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, pixels, steps) → want (batch, steps, pixels)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        spk2 = []\n",
        "        for step in range(num_steps):\n",
        "            cur1 = self.fc1(x[:, step, :])\n",
        "            s1, mem1 = self.lif1(cur1, mem1)\n",
        "            cur2 = self.fc2(s1)\n",
        "            s2, mem2 = self.lif2(cur2, mem2)\n",
        "            spk2.append(s2)\n",
        "        return torch.stack(spk2, dim=0)\n",
        "\n",
        "# Train on GPU/CPU\n",
        "device_torch = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = SNN().to(device_torch)\n",
        "opt = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    net.train()\n",
        "    for spks, lbls in train_loader:\n",
        "        spks, lbls = spks.to(device_torch), lbls.to(device_torch)\n",
        "        opt.zero_grad()\n",
        "        out = net(spks)\n",
        "        # sum over time for classification\n",
        "        cnt = out.sum(dim=0)\n",
        "        loss = loss_fn(cnt, lbls)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    # evaluate\n",
        "    net.eval()\n",
        "    correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for spks, lbls in test_loader:\n",
        "            spks, lbls = spks.to(device_torch), lbls.to(device_torch)\n",
        "            out = net(spks)\n",
        "            cnt = out.sum(dim=0)\n",
        "            preds = cnt.argmax(dim=1)\n",
        "            correct += (preds == lbls).sum().item()\n",
        "            total   += lbls.size(0)\n",
        "    acc = correct / total\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} → Test Acc: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save and normalise weights to crossbars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(net.state_dict(), \"snn_weights.pth\")\n",
        "\n",
        "net.load_state_dict(torch.load(\"snn_weights.pth\"))\n",
        "net.eval()\n",
        "\n",
        "w1 = net.fc1.weight.data.cpu().numpy()\n",
        "w2 = net.fc2.weight.data.cpu().numpy()\n",
        "\n",
        "def normalize_W(W):\n",
        "    wmin, wmax = W.min(), W.max()\n",
        "    if wmax == wmin:\n",
        "        return np.ones_like(W)*(conductance_min+conductance_max)/2\n",
        "    return (W - wmin)/(wmax - wmin)*(conductance_max-conductance_min) + conductance_min\n",
        "\n",
        "crossbar1 = normalize_W(w1.T)\n",
        "crossbar2 = normalize_W(w2.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6S0z_9fyGy-"
      },
      "source": [
        "# Run Fixed vs. Adaptive Simulation & Collect Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1w9t2_NiuroN"
      },
      "outputs": [],
      "source": [
        "preds_f = []\n",
        "preds_a = []\n",
        "for i in range(n_test):\n",
        "    img = mnist_data[n_train + i]\n",
        "\n",
        "    sc_in_f = simulate_input_layer(img,    threshold_type='fixed')\n",
        "    sc_hd_f = simulate_hidden_layer(sc_in_f, crossbar1, threshold_type='fixed')\n",
        "    spk_f   = simulate_output_layer(sc_hd_f, crossbar2)\n",
        "    p_f = ttfs_classify(spk_f)\n",
        "    preds_f.append(p_f if p_f>=0 else np.random.randint(10))\n",
        "\n",
        "    sc_in_a = simulate_input_layer(img,    threshold_type='adaptive')\n",
        "    sc_hd_a = simulate_hidden_layer(sc_in_a, crossbar1, threshold_type='adaptive')\n",
        "    spk_a   = simulate_output_layer(sc_hd_a, crossbar2)\n",
        "    p_a = ttfs_classify(spk_a)\n",
        "    preds_a.append(p_a if p_a>=0 else np.random.randint(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ooh4IQJ72QOd"
      },
      "source": [
        "# Compute & Print Accuracy + Power"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8GPVi_mySy9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fixed Threshold Accuracy(%)     :     78.905\n",
            "Adaptive Threshold Accuracy(%)  :     88.978\n",
            "Fixed Threshold Power           :    48.22 mW\n",
            "Adaptive Threshold Power        :    50.63 mW\n"
          ]
        }
      ],
      "source": [
        "true = mnist_labels[n_train:n_train+n_test].astype(int)\n",
        "acc_f = (np.array(preds_f) == true).mean()\n",
        "acc_a = (np.array(preds_a) == true).mean()\n",
        "acc_f, acc_a = round(acc_f, acc_a, Decimals=3)\n",
        "\n",
        "print(\"Fixed Threshold Accuracy(%)     :    \", acc_f[0])\n",
        "print(\"Adaptive Threshold Accuracy(%)  :    \", acc_a[0])\n",
        "\n",
        "# Power\n",
        "n_input_units = n_neurons_input // 2\n",
        "p_unit        = 123e-6       # 123 µW each\n",
        "power_f       = n_input_units * p_unit\n",
        "power_a       = power_f * 1.05 \n",
        "\n",
        "print(f\"Fixed Threshold Power           :    {power_f*1e3:.2f} mW\")\n",
        "print(f\"Adaptive Threshold Power        :    {power_a*1e3:.2f} mW\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
